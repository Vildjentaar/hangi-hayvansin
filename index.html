<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>VERİ BİLİMİ</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700;900&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            background-color: #1f2937;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            padding: 1rem;
        }

        /* Video/Canvas Base Styling (Mirror Effect Applied via draw) */
        #video, #output_canvas {
            transform: none;
            -webkit-transform: none;
            max-width: 100%;
            height: 100%;
            border-radius: 0.75rem;
            box-shadow: 0 4px 6px -1px rgba(0,0,0,0.1), 0 2px 4px -1px rgba(0,0,0,0.06);
        }
        #video { display: none; } /* we draw video into canvas */

        /* Container uses aspect-ratio set from JS */
        #video_container {
            width: 100%;
            aspect-ratio: 16 / 9; /* default, overridden by JS on load */
        }

        /* Spinner animation */
        .spinning { animation: pulse 1s infinite; }
        @keyframes pulse {
            0%, 100% { transform: scale(1); } 50% { transform: scale(1.05); }
        }
        #roulette_result_container { min-height: 250px; display:flex; justify-content:center; align-items:center; }
        #result_image { transition: opacity .3s ease-in-out; object-fit: cover; }
    </style>
</head>
<body>
    <div id="app" class="w-full max-w-4xl bg-gray-100/75 p-8 rounded-2xl shadow-2xl space-y-8">
        <h1 class="text-4xl font-extrabold text-center text-indigo-700">Tipine Göre Hangi Hayvansın?</h1>
        <p id="status_message" class="text-center text-gray-600">Kamera Yükleniyor...</p>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
            <div id="video_container" class="relative rounded-xl overflow-hidden shadow-lg">
                <video id="video" playsinline autoplay></video>
                <canvas id="output_canvas" class="absolute top-0 left-0 w-full h-full"></canvas>
                <div id="loading_indicator" class="absolute inset-0 flex flex-col items-center justify-center bg-gray-100/75 rounded-xl transition duration-500">
                    <svg class="animate-spin h-8 w-8 text-indigo-500 mb-3" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                    </svg>
                    <span class="text-indigo-600 font-semibold">Loading...</span>
                </div>
            </div>

            <div class="bg-indigo-50 p-6 rounded-xl border-4 border-indigo-200 flex flex-col justify-between">
                <div>
                    <h2 class="text-2xl font-bold text-indigo-800 mb-4 text-center">Senin hayvanın:</h2>
                    <div id="roulette_result_container" class="mb-4">
                        <img id="result_image" src="CATS/BAĞIRAN KEDİ.png" alt="Roulette Başlangıç Görseli" class="w-124 h-72 object-cover shadow-lg border-4 border-indigo-400 opacity-100">
                    </div>
                </div>

                <div class="text-center">
                    <button id="spin_button" disabled class="w-full py-4 text-xl font-extrabold rounded-lg transition duration-300 shadow-xl disabled:bg-gray-400 disabled:text-gray-200 disabled:cursor-not-allowed bg-yellow-500 hover:bg-yellow-600 text-white transform hover:scale-[1.02] active:scale-[0.98]">
                        Yüz Aranıyor...
                    </button>
                    <p id="face_status" class="mt-2 text-sm text-gray-500"></p>
                </div>
            </div>
        </div>
    </div>

<script>
    let model, video, canvas, ctx;
    let running = false, faceDetected = false, isSpinning = false, spinInterval;
    const statusMessage = document.getElementById('status_message');
    const loadingIndicator = document.getElementById('loading_indicator');
    const spinButton = document.getElementById('spin_button');
    const resultImage = document.getElementById('result_image');
    const faceStatus = document.getElementById('face_status');
    const videoContainer = document.getElementById('video_container');

    const ANIMAL_IMAGES = [
        { type: 'CAT', url: 'CATS/BAĞIRAN KEDİ.png', active: true },
        /* ... (rest of images omitted for brevity - keep your full array) ... */
    ];
    // If you paste full array, keep the original list.

    // utility to detect mobile/phone (simple and robust)
    function isMobileDevice() {
        const ua = navigator.userAgent || navigator.vendor || window.opera;
        // Basic UA checks + screen width fallback
        return /Mobi|Android|iPhone|iPad|Phone/i.test(ua) || window.innerWidth <= 800;
    }

    // stop any active tracks on the current video stream
    function stopCurrentStream() {
        if (video && video.srcObject) {
            const tracks = video.srcObject.getTracks();
            tracks.forEach(t => t.stop());
            video.srcObject = null;
        }
    }

    /**
     * Sets the container aspect-ratio CSS to either 16/9 or 9/16 depending on device.
     */
    function applyContainerAspect() {
        if (isMobileDevice()) {
            videoContainer.style.aspectRatio = '9 / 16';
        } else {
            videoContainer.style.aspectRatio = '16 / 9';
        }
    }

    /**
     * Initializes/requests camera with friendly constraints for the detected device.
     * Uses ideal width/height instead of exact aspectRatio constraints for better compatibility.
     */
    async function setupCamera() {
        statusMessage.textContent = "Requesting camera access...";
        video = document.getElementById('video');
        canvas = document.getElementById('output_canvas');
        ctx = canvas.getContext('2d');

        applyContainerAspect();

        // If already streaming, stop and re-request with new constraints (useful on orientation change)
        stopCurrentStream();

        // Choose ideal width/height depending on orientation detection
        const mobile = isMobileDevice();
        // These are "ideal" requests; browser will try to satisfy but won't error out if exact ratio not supported
        let videoConstraints;
        if (mobile) {
            videoConstraints = { width: { ideal: 720 }, height: { ideal: 1280 } }; // portrait ideal
        } else {
            videoConstraints = { width: { ideal: 1280 }, height: { ideal: 720 } }; // landscape ideal
        }

        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: false,
                video: Object.assign({ facingMode: 'user' }, videoConstraints)
            });

            video.srcObject = stream;

            await new Promise(resolve => {
                video.onloadedmetadata = () => {
                    // Set canvas real pixel size to match video resolution
                    canvas.width = video.videoWidth || (mobile ? 720 : 1280);
                    canvas.height = video.videoHeight || (mobile ? 1280 : 720);

                    // ensure CSS fills the container
                    canvas.style.width = '100%';
                    canvas.style.height = '100%';
                    video.width = canvas.width;
                    video.height = canvas.height;
                    resolve();
                };
            });

            statusMessage.textContent = "Kamera aktif, devam ediliyor...";
            return true;
        } catch (err) {
            console.error("Kameraya erişilemedi:", err);
            statusMessage.textContent = "HATA: Kameraya erişilemedi. Lütfen kamera izinlerini aktif edin.";
            return false;
        }
    }

    async function loadModel() {
        try {
            model = await blazeface.load();
            statusMessage.textContent = "Başlamak için poz verin!";
            loadingIndicator.style.opacity = '0';
            setTimeout(() => { loadingIndicator.style.display = 'none'; }, 500);
            running = true;
            predict();
        } catch (err) {
            console.error("Error loading model:", err);
            statusMessage.textContent = "Error: Failed to load face detection model.";
        }
    }

    async function predict() {
        if (!running || isSpinning) {
            requestAnimationFrame(predict);
            return;
        }
        let detections = [];
        if (model && video && video.readyState === 4) {
            detections = await model.estimateFaces(video, false);
        }
        drawVideo(detections);
        const currentFaceDetected = detections.length > 0;
        if (currentFaceDetected !== faceDetected) {
            faceDetected = currentFaceDetected;
            updateButtonStatus();
        }
        requestAnimationFrame(predict);
    }

    function updateButtonStatus() {
        if (faceDetected) {
            spinButton.disabled = false;
            spinButton.textContent = "BAŞLA!";
            faceStatus.textContent = "Yüz tespit edildi. Başlamaya hazırız!";
        } else {
            spinButton.disabled = true;
            spinButton.textContent = "Başlamak için yüz aranıyor.";
            faceStatus.textContent = "Lütfen yüzünüzü ortalayın.";
        }
    }

    function drawVideo(detections) {
        if (!canvas || !ctx || !video) return;
        // If canvas pixel size differs from displayed size, ensure drawing uses canvas pixel size
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // Mirror draw (flip horizontally)
        ctx.save();
        ctx.scale(-1, 1);
        ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
        ctx.restore();

        if (detections.length > 0) {
            const detection = detections[0];
            const start = detection.topLeft;
            const end = detection.bottomRight;
            const size = [end[0] - start[0], end[1] - start[1]];

            // Adjust coordinates because we drew mirrored
            const adjustedX = canvas.width - end[0];
            const adjustedY = start[1];
            const adjustedWidth = size[0];
            const adjustedHeight = size[1];

            ctx.beginPath();
            ctx.strokeStyle = '#3b82f6';
            ctx.lineWidth = 4;
            ctx.rect(adjustedX, adjustedY, adjustedWidth, adjustedHeight);
            ctx.stroke();

            ctx.fillStyle = '#ef3333';
            detection.landmarks.forEach(point => {
                const pointAdjX = canvas.width - point[0];
                ctx.beginPath();
                ctx.arc(pointAdjX, point[1], 4, 0, 2 * Math.PI);
                ctx.fill();
            });
        }
    }

    function spinRoulette() {
        const activeImages = ANIMAL_IMAGES.filter(img => img.active);
        if (isSpinning || activeImages.length === 0) return;

        isSpinning = true;
        spinButton.disabled = true;
        spinButton.textContent = ". . .";
        spinButton.classList.add('spinning');
        resultImage.style.opacity = 1;

        let spinCount = 0;
        const totalSpinDuration = 3100;
        let cycleDelay = 67;

        spinInterval = setInterval(() => {
            const idx = Math.floor(Math.random() * activeImages.length);
            const currentAnimal = activeImages[idx];
            resultImage.src = currentAnimal.url;
            resultImage.alt = currentAnimal.type;

            spinCount += cycleDelay;
            if (spinCount < totalSpinDuration * 0.5) {
                cycleDelay = 50;
            } else if (spinCount < totalSpinDuration * 0.8) {
                cycleDelay = 100;
            } else {
                cycleDelay = 200;
            }

            if (spinCount >= totalSpinDuration) {
                clearInterval(spinInterval);
                finalizeResult();
            }
        }, cycleDelay);
    }

    function finalizeResult() {
        const activeImages = ANIMAL_IMAGES.filter(img => img.active);
        const finalIndex = Math.floor(Math.random() * activeImages.length);
        const finalAnimal = activeImages[finalIndex];
        const fullPath = finalAnimal.url;
        const matches = fullPath.match(/[^/\\?#]+\.[^/\\?#]+$/);
        const fullFileName = matches ? matches[0] : fullPath.split('/').pop();
        const fileNameWithoutExt = fullFileName.split('.').slice(0, -1).join('.');
        resultImage.src = finalAnimal.url;
        resultImage.alt = finalAnimal.type;
        resultImage.style.opacity = 1;
        spinButton.textContent = `${fileNameWithoutExt}`;
        spinButton.classList.remove('spinning');

        setTimeout(() => {
            isSpinning = false;
            updateButtonStatus();
        }, 4200);
    }

    window.onload = async () => {
        spinButton.addEventListener('click', spinRoulette);

        // initial camera + model load
        const cameraReady = await setupCamera();
        if (cameraReady) {
            await loadModel();
        }

        // Restart camera on orientation change (mobile) or when device size changes significantly
        let lastMobileFlag = isMobileDevice();
        window.addEventListener('orientationchange', async () => {
            // small debounce
            setTimeout(async () => {
                const nowMobile = isMobileDevice();
                if (nowMobile !== lastMobileFlag) {
                    lastMobileFlag = nowMobile;
                    // restart camera to apply new constraints/aspect
                    const ready = await setupCamera();
                    if (!model && ready) await loadModel();
                } else {
                    // even if mobile flag didn't change, reapply container aspect if needed
                    applyContainerAspect();
                }
            }, 300);
        });

        // Also handle window resize that crosses the mobile threshold
        window.addEventListener('resize', async () => {
            const nowMobile = isMobileDevice();
            if (nowMobile !== lastMobileFlag) {
                lastMobileFlag = nowMobile;
                const ready = await setupCamera();
                if (!model && ready) await loadModel();
            } else {
                applyContainerAspect();
            }
        });
    };

    // ensure canvas keeps video size on manual resize
    window.addEventListener('resize', () => {
        if (video && video.videoWidth > 0 && canvas) {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
        }
    });
</script>
</body>
</html>
