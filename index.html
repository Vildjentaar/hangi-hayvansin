<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VERİ BİLİMİ</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- MediaPipe face detection + helpers -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <!-- Optional: drawing utils if you want Mediapipe helpers (or draw yourself) -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>


    <style>
        /* Custom font and basic body style */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700;900&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            background-color: #1f2937; /* Dark background */
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            padding: 1rem;
        }
        /* Style for the video and canvas to be contained and responsive */
        #video, #output_canvas {
            transform: none; 
            -webkit-transform: none; 
            max-width: 100%;
            height: auto;
            border-radius: 0.75rem;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        }
        
        /* FIX: Ensure video is positioned absolutely but NOT hidden */
        #video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        #output_canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        /* Spinner button animation */
        .spinning {
            animation: pulse 1.1s infinite;
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        /* Image container for the roulette result */
        #roulette_result_container {
            min-height: 250px;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        #result_image {
            transition: opacity 0.3s ease-in-out;
            object-fit: cover;
        }
    </style>
</head>
<body>

    <div id="app" class="w-full max-w-4xl bg-gray-100/65 p-8 rounded-2xl shadow-2xl space-y-8">
        <h1 class="text-4xl font-extrabold text-center text-indigo-700">Tipine Göre Hangi Hayvansın?</h1>
        <p id="status_message" class="text-center text-gray-600">Kamera Yükleniyor...</p>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
            
            <!-- Video/Canvas Feed (Now 4:3 Aspect Ratio) -->
            <div class="relative w-full aspect-[4/3] rounded-xl overflow-hidden shadow-lg">
                <!-- Video is now visible but covered by canvas -->
                <video id="video" playsinline autoplay></video>
                <canvas id="output_canvas"></canvas>
                <div id="loading_indicator" class="absolute inset-0 flex flex-col items-center justify-center bg-gray-100/75 rounded-xl transition duration-500">
                    <svg class="animate-spin h-8 w-8 text-indigo-500 mb-3" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                    </svg>
                    <span class="text-indigo-600 font-semibold">Loading...</span>
                </div>
            </div>

            <!-- Roulette Result Panel -->
            <div class="bg-indigo-50 p-6 rounded-xl border-4 border-indigo-200 flex flex-col justify-between">
                <div>
                    <h2 class="text-2xl font-bold text-indigo-800 mb-4 text-center">Senin hayvanın:</h2>
                    <div id="roulette_result_container" class="mb-4">
                        <!-- UPDATED: Initial placeholder set to a local image path -->
                        <img id="result_image" src="CATS/placeholder.png" alt="Roulette Başlangıç Görseli" class="w-124 h-72 object-cover shadow-lg border-4 border-indigo-400 opacity-100">
                    </div>
                </div>

                <div class="text-center">
                    <button id="spin_button" 
                            disabled 
                            class="w-full py-4 text-xl font-extrabold rounded-lg transition duration-300 shadow-xl 
                                   disabled:bg-gray-400 disabled:text-gray-200 disabled:cursor-not-allowed
                                   bg-yellow-500 hover:bg-yellow-600 text-white transform hover:scale-[1.02] active:scale-[0.98]">
                        Yüz Aranıyor...
                    </button>
                    <p id="face_status" class="mt-2 text-sm text-gray-500"></p>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Global variables and configuration
        let model;
        let video;
        let canvas;
        let ctx;
        let running = false;
        let faceDetected = false;
        let isSpinning = false;
        let spinInterval;

        // DOM element references
        const statusMessage = document.getElementById('status_message');
        const loadingIndicator = document.getElementById('loading_indicator');
        const spinButton = document.getElementById('spin_button');
        const resultImage = document.getElementById('result_image');
        const faceStatus = document.getElementById('face_status');

        // Hardcoded list of images 
        // NOTE: For images to load, the 'CATS' and 'DOGS' folders MUST be located 
        // in the same directory as this index.html file.
        const ANIMAL_IMAGES = [
            // --- CATS ---
            { type: 'CAT', url: 'CATS/BAĞIRAN KEDİ.png', active: false },
            { type: 'CAT', url: 'CATS/Bahtsız Kedi.png', active: true },
            { type: 'CAT', url: 'CATS/Duran Kedi.png', active: false },
            { type: 'CAT', url: 'CATS/Gamer Kedi.png', active: false },
            { type: 'CAT', url: 'CATS/Kırgın Kedi....png', active: false },
            { type: 'CAT', url: 'CATS/KORKMUŞ KEDİ.png', active: false },
            { type: 'CAT', url: 'CATS/Köylü Kedi.png', active: false },
            { type: 'CAT', url: 'CATS/Menajer Kedi.png', active: false },
            { type: 'CAT', url: 'CATS/Minecraft Keddy.png', active: false },
            { type: 'CAT', url: 'CATS/Punk Kedi!.png', active: false },
            { type: 'CAT', url: 'CATS/Romantik Keddy.png', active: false },
            { type: 'CAT', url: 'CATS/şÜPHELİ kEDİ.png', active: false },
            { type: 'CAT', url: 'CATS/TOST KEDDY.png', active: false },
            { type: 'CAT', url: 'CATS/Uzaylı Kedi.png', active: false },
            
            // --- DOGS ---
            { type: 'DOG', url: 'DOGS/Akbaş.png', active: true },
            { type: 'DOG', url: 'DOGS/Arap Köpeği.png', active: false },
            { type: 'DOG', url: 'DOGS/Dişil Enerji Köpek.png', active: false },
            { type: 'DOG', url: 'DOGS/Enik Köpek.png', active: false },
            { type: 'DOG', url: 'DOGS/Huzurlu Köpek.png', active: true },
            { type: 'DOG', url: 'DOGS/Issız Köpek.png', active: false },
            { type: 'DOG', url: 'DOGS/Mazlum Köpek.png', active: true },
            { type: 'DOG', url: 'DOGS/Romantik Köpiş.png', active: false },
            { type: 'DOG', url: 'DOGS/Sırıtan Köpek.png', active: false },
            { type: 'DOG', url: 'DOGS/Yarışçı Köpek.png', active: false },
            { type: 'DOG', url: 'DOGS/Aşçı Köpek.png', active: true },
            { type: 'DOG', url: 'DOGS/DOG RIDER.png', active: true },
            { type: 'DOG', url: 'DOGS/Fakir Köpke.png', active: false },
            { type: 'DOG', url: 'DOGS/Hawlı Köpek.png', active: false },
            { type: 'DOG', url: 'DOGS/Miğferli Köpek.png', active: true },
            { type: 'DOG', url: 'DOGS/Minecraft Doggy.png', active: false },
            { type: 'DOG', url: 'DOGS/Şaşırmış Köpek.png', active: false },
            { type: 'DOG', url: 'DOGS/Şüpheli Köpek.png', active: true },
            { type: 'DOG', url: 'DOGS/TOST KÖPEK.png', active: false },
            { type: 'DOG', url: 'DOGS/Yönetici Köpek.png', active: false },
        ];
        
        // This function is no longer necessary since we use the active flag to manage images
        function setAnimalImages(newImages) {
             ANIMAL_IMAGES.splice(0, ANIMAL_IMAGES.length, ...newImages); // Overwrite the array
        }

        /**
         * Initializes the video stream from the camera.
         */
        async function setupCamera() {
            statusMessage.textContent = "Requesting camera access...";
            video = document.getElementById('video');
            canvas = document.getElementById('output_canvas');
            ctx = canvas.getContext('2d');

            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    'audio': false,
                    'video': { facingMode: 'user' }
                });

                video.srcObject = stream;
                await new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        video.width = video.videoWidth;
                        video.height = video.videoHeight;
                        resolve(video);
                    };
                });
                statusMessage.textContent = "Kamera aktif, devam ediliyor...";
            } catch (error) {
                console.error("Kameraya erişilemedi:", error);
                statusMessage.textContent = "HATA: Kameraya erişilemedi. Lütfen kamera izinlerini aktif edin.";
                return false;
            }
            return true;
        }

        /**
         * Loads the BlazeFace model from TensorFlow.js.
         */
  // --- MediaPipe-based face detection replacement ---

  let faceDetection;    // MediaPipe FaceDetection instance
  let mpCamera;         // MediaPipe Camera helper (controls loop)
  let latestDetections = []; // keep last detections for drawVideo compatibility

  async function initMediaPipe() {
    // Create FaceDetection; locateFile points to CDN files
    faceDetection = new FaceDetection({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`
    });

    // Options: model can be "short" (fast) or "full" (slower, longer range)
    faceDetection.setOptions({
      model: 'short',                // 'short' is faster and usually fine for webcam
      minDetectionConfidence: 0.5
    });

    // onResults is called every time MediaPipe produces output
    faceDetection.onResults(onMpResults);

    // Start camera loop via Camera utility (runs onFrame -> faceDetection.send)
    // It handles the requestAnimationFrame loop for us and is efficient.
    mpCamera = new Camera(video, {
      onFrame: async () => {
        // send current video frame to MediaPipe
        await faceDetection.send({image: video});
      },
      width: 1280,
      height: 720
    });

    // start the camera
    await mpCamera.start();

    // update UI
    statusMessage.textContent = "Başlamak için poz verin!";
    loadingIndicator.style.opacity = '0';
    setTimeout(() => { loadingIndicator.style.display = 'none'; }, 500);
    running = true; // keep your existing flags consistent
    // No manual predict loop needed; drawing is triggered from onResults
  }

  /**
   * MediaPipe results handler.
   * results.detections is an array; each detection has boundingBox and landmarks.
   * We store detections to let your existing drawVideo function render them.
   */
  function onMpResults(results) {
    // results.image is the input frame (we draw video separately, so not required)
    latestDetections = results.detections || [];

    // Update the faceDetected flag & button status
    const currentFaceDetected = latestDetections.length > 0;
    if (currentFaceDetected !== faceDetected) {
      faceDetected = currentFaceDetected;
      updateButtonStatus();
    }

    // Draw - reuse your drawVideo but pass a conversions-friendly object
    // Convert mediapipe detections to an array with expected fields
    const converted = latestDetections.map(det => {
      // boundingBox might be in pixels (originX/originY/width/height) or normalized.
      const box = det.boundingBox || {};
      // If boundingBox.width is <=1 assume normalized coords (0..1)
      const isNormalized = (box.width && box.width <= 1);

      const bb = {
        originX: box.originX ?? (box.xCenter ? box.xCenter - (box.width/2) : 0),
        originY: box.originY ?? 0,
        width: box.width ?? 0,
        height: box.height ?? 0,
        normalized: isNormalized
      };

      // some mediapipe builds place landmark arrays in det.landmarks or det.keypoints
      const rawLandmarks = det.landmarks || det.keypoints || [];
      const landmarks = rawLandmarks.map(p => ({x: p.x, y: p.y}));

      return { boundingBox: bb, landmarks };
    });

    // call existing drawing helper but adapted for MediaPipe coordinates
    drawVideoFromMp(converted);
  }

  /**
   * Draw function for MediaPipe detections that mirrors the video (like your original).
   * Accepts array where each item: { boundingBox: {originX,originY,width,height,normalized}, landmarks: [{x,y}] }
   */
  function drawVideoFromMp(detections) {
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // Draw mirrored video (like before)
    ctx.save();
    ctx.scale(-1, 1);
    ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
    ctx.restore();

    if (!detections || detections.length === 0) return;

    const det = detections[0]; // first face
    let { originX, originY, width: w, height: h, normalized } = det.boundingBox;

    // 1. If normalized coordinates, convert to pixels
    if (normalized) {
      originX = originX * canvas.width;
      originY = originY * canvas.height;
      w = w * canvas.width;
      h = h * canvas.height;
    }
    
    // 2. Horizontal Mirroring
    const mirroredX = canvas.width - (originX + w);

    // 3. Vertical Correction FIX: Compensate for MediaPipe's box starting too high.
    // Shift the box down by 5% of its height to center it better around the actual face features.
    const verticalShift = h * 0.05; 
    let finalOriginY = originY + verticalShift;


    // --- BLUE BOX REMOVED ---
    /*
    ctx.beginPath();
    ctx.strokeStyle = '#3b82f6';
    ctx.lineWidth = 4;
    ctx.rect(mirroredX, finalOriginY, w, h); // Use shifted Y coordinate
    ctx.stroke();
    */
    // --- END BLUE BOX REMOVED ---

    // Draw landmarks (mirror X)
    ctx.fillStyle = '#ef4444';
    (det.landmarks || []).forEach(pt => {
      let px = pt.x, py = pt.y;
      // If normalized coordinates convert
      if (det.boundingBox.normalized) {
        px = px * canvas.width;
        py = py * canvas.height;
      }
      // Apply horizontal flip to landmark X coordinate
      const mirroredPx = canvas.width - px;
      // Note: We don't apply vertical shift to the landmarks because their Y coordinates
      // are correct relative to the face features, and the shift is only compensating the box.
      ctx.beginPath();
      ctx.arc(mirroredPx, py, 4, 0, 2 * Math.PI);
      ctx.fill();
    });
  }

  // --- Hook into your window.onload flow ---
  window.addEventListener('load', async () => {
    // keep the event listener you already had for spin button
    spinButton.addEventListener('click', spinRoulette);

    // Setup camera metadata (only needed so canvas sizing works)
    const camOk = await setupCamera(); // re-use your existing setupCamera which sets canvas sizes
    if (camOk) {
      // Initialize MediaPipe detector instead of TFJS/blazeface
      await initMediaPipe();
    } else {
      statusMessage.textContent = "Kamera bulunamadı veya izin reddedildi.";
    }
  });

  // On window resize keep canvas size synced (unchanged)
  window.addEventListener('resize', () => {
    if (video && video.videoWidth > 0) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }
  });



        /**
         * Simulates the roulette spinning action.
         */
        function spinRoulette() {
            // Filter the active images for the spin
            const activeImages = ANIMAL_IMAGES.filter(img => img.active);

            // Use the static ANIMAL_IMAGES array
            if (isSpinning || activeImages.length === 0) return;
            
            isSpinning = true;
            spinButton.disabled = true;
            spinButton.textContent = ". . .";
            spinButton.classList.add('spinning');
            resultImage.style.opacity = 1;

            let spinCount = 0;
            const totalSpinDuration = 3100; // Spin for 3 seconds
            let cycleDelay = 67; // Initial delay in milliseconds

            // The roulette cycling function
            spinInterval = setInterval(() => {
                const randomIndex = Math.floor(Math.random() * activeImages.length);
                const currentAnimal = activeImages[randomIndex];
                resultImage.src = currentAnimal.url;
                resultImage.alt = currentAnimal.type;
                
                spinCount += cycleDelay;

                // Gradually slow down the spin
                if (spinCount < totalSpinDuration * 0.5) {
                    cycleDelay = 50;
                } else if (spinCount < totalSpinDuration * 0.8) {
                    cycleDelay = 100;
                } else {
                    cycleDelay = 200;
                }
                
                // If duration reached, stop the spinning
                if (spinCount >= totalSpinDuration) {
                    clearInterval(spinInterval);
                    finalizeResult();
                }
            }, cycleDelay);
        }

        /**
         * Determines the final random result and updates the UI.
         */
        function finalizeResult() {
            // Filter the active images for the result
            const activeImages = ANIMAL_IMAGES.filter(img => img.active);
            
            // Use the filtered activeImages array
            const finalIndex = Math.floor(Math.random() * activeImages.length);
            const finalAnimal = activeImages[finalIndex];

            // --- Logic to Extract Filename without path or extension ---
            // 1. Get the full path (e.g., 'DOGS/DOG RIDER.jpg')
            const fullPath = finalAnimal.url;
            // 2. Extract the base filename (e.g., 'DOG RIDER.jpg')
            // Using a regex to grab the last part after a slash.
            const matches = fullPath.match(/[^/\\?#]+\.[^/\\?#]+$/);
            const fullFileName = matches ? matches[0] : fullPath.split('/').pop();
            
            // 3. Remove the extension (e.g., 'DOG RIDER')
            const fileNameWithoutExt = fullFileName.split('.').slice(0, -1).join('.');

            // Ensure the final image is displayed clearly
            resultImage.src = finalAnimal.url;
            resultImage.alt = finalAnimal.type;
            resultImage.style.opacity = 1;
            
            // Updated text to show the filename
            spinButton.textContent = `${fileNameWithoutExt}`;
            spinButton.classList.remove('spinning');
            
            // Re-enable button
            setTimeout(() => {
                isSpinning = false;
                // Only re-enable if a face is still detected
                updateButtonStatus(); 
            }, 4200); // Wait briefly before allowing re-spin
        }

        /**
         * Updates the state of the Spin button based on face detection.
         */
        function updateButtonStatus() {
            if (faceDetected) {
                spinButton.disabled = false;
                spinButton.textContent = "BAŞLA!";
                faceStatus.textContent = "Yüz tespit edildi. Başlamaya hazırız!";
            } else {
                spinButton.disabled = true;
                spinButton.textContent = "Başlamak için yüz aranıyor.";
                faceStatus.textContent = "Lütfen yüzünüzü ortalayın.";
            }
        }
    </script>


</body>
</html>
